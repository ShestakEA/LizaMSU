{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов с помощью наивного байесовского классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "* [Наивный байесовский классификатор](#Наивный-байесовский-классификатор)\n",
    "* [Датасет](#Датасет)\n",
    "* [Векторное представление текста](#Векторное-представление-текста)\n",
    "* [BernoulliNB](#BernoulliNB)\n",
    "* [Модель Bag-of-Words](#Модель-Bag-of-Words)\n",
    "* [MultinomialNB](#MultinomialNB)\n",
    "* [TF-IDF](#TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\textbf{x}_i = (x_{i1}, ..., x_{im})$ - вектор признаков для $i$-го элемента датасета, $y_i$ - соответствующий класс. Ключевое предположение наивного байесовского классификатора - независимость признаков при заданном классе, т.е. \n",
    "![p(\\textbf{x}_i | y_i=c) = p(x_{i1} | y_i=c)\\cdot...\\cdot p(x_{im} | y_i=c).](https://latex.codecogs.com/gif.latex?%5Cbg_white%20p%28%5Ctextbf%7Bx%7D_i%20%7C%20y_i%3Dc%29%20%3D%20p%28x_%7Bi1%7D%20%7C%20y_i%3Dc%29%5Ccdot...%5Ccdot%20p%28x_%7Bim%7D%20%7C%20y_i%3Dc%29.)\n",
    "\n",
    "В таком предположении совместная плотность для $i$-го элемента датасета распишется как\n",
    "![\\bg_white p(\\textbf{x}_i, y_i) = p(y_i)\\prod\\limits_{j=1}^{m} p(x_{ij} | y_i) = \\prod\\limits_{c=1}^{C}\\pi_c^{\\textrm{I}(y_i=c)}\\prod\\limits_{j=1}^{m}\\prod\\limits_{c=1}^{C} p(x_{ij} | \\theta_{jc})^{\\textrm{I}(y_i=c)}](https://latex.codecogs.com/gif.latex?%5Cbg_white%20p%28%5Ctextbf%7Bx%7D_i%2C%20y_i%29%20%3D%20p%28y_i%29%5Cprod%5Climits_%7Bj%3D1%7D%5E%7Bm%7D%20p%28x_%7Bij%7D%20%7C%20y_i%29%20%3D%20%5Cprod%5Climits_%7Bc%3D1%7D%5E%7BC%7D%5Cpi_c%5E%7B%5Ctextrm%7BI%7D%28y_i%3Dc%29%7D%5Cprod%5Climits_%7Bj%3D1%7D%5E%7Bm%7D%5Cprod%5Climits_%7Bc%3D1%7D%5E%7BC%7D%20p%28x_%7Bij%7D%20%7C%20%5Ctheta_%7Bjc%7D%29%5E%7B%5Ctextrm%7BI%7D%28y_i%3Dc%29%7D)\n",
    "\n",
    "Для бинарных признаков будем полагать $p(x_{ij} | \\theta_{jc})$ распределеинем Бернулли с параметром $\\theta_{jc}$, для признаков, принимающих значения в некотором конечном наборе значений, полагаем $p(x_{ij} | \\theta_{jc})$ категориальным распределением с параметром  $\\theta_{jc}$ в виде вектора.\n",
    "\n",
    "Для простоты рассмотрим модель с бинарными признаками. Для параметра $\\pi$ категориального распределения класса и параметров $\\theta_{jc}$ бернулиевских распределений признаков внутри класса выберем соответствующие априорные распределения:\n",
    "\n",
    "* $p(\\pi | \\alpha) \\sim Dir(\\alpha)$\n",
    "* $p(\\theta_{jc} | \\beta) \\sim Beta(\\beta_0, \\beta_1)$.\n",
    "\n",
    "При таком выборе априорных распределений легко получить апостериорные распределения:\n",
    "* $p(\\pi | D) \\sim Dir(\\alpha_1 + N_1, ... ,\\alpha_C + N_C)$\n",
    "* $p(\\theta_{jc} | D) \\sim Beta(\\beta_0 + N_{jc}, \\beta_1 + (N_c - N_{jc}))$,\n",
    "\n",
    "где $D$ - датасет, $N_c$ - количество элементов датасета, относящихся к классу $c$, $N_{jc}$ - количество наблюдений признака $j$ внутри класса $c$.\n",
    "\n",
    "Опишем процедуру расчета вероятности $p(y=c|\\textbf{x}, D)$:\n",
    "![p(y=c|\\textbf{x}, D) \\propto \\int p(y=c|\\pi)p(\\pi | D) \\prod\\limits_{j=1}^{m} p(\\textbf{x}_{jc} | \\theta_{jc}) p(\\theta_{jc} | D) \\textrm{d} \\pi \\textrm{d} \\theta_{jc} = \\newline = \\int \\pi_cp(\\pi | D) \\textrm{d} \\pi \\prod\\limits_{j=1}^{m} \\int \\theta_{jc}^{\\textrm{I}(x_{jc}=1)}(1 - \\theta_{jc})^{\\textrm{I}(x_{jc}=0)} p(\\theta_{jc} | D) \\textrm{d} \\theta_{jc}.](https://latex.codecogs.com/gif.latex?p%28y%3Dc%7C%5Ctextbf%7Bx%7D%2C%20D%29%20%5Cpropto%20%5Cint%20p%28y%3Dc%7C%5Cpi%29p%28%5Cpi%20%7C%20D%29%20%5Cprod%5Climits_%7Bj%3D1%7D%5E%7Bm%7D%20p%28%5Ctextbf%7Bx%7D_%7Bjc%7D%20%7C%20%5Ctheta_%7Bjc%7D%29%20p%28%5Ctheta_%7Bjc%7D%20%7C%20D%29%20%5Ctextrm%7Bd%7D%20%5Cpi%20%5Ctextrm%7Bd%7D%20%5Ctheta_%7Bjc%7D%20%3D%20%5Cnewline%20%3D%20%5Cint%20%5Cpi_cp%28%5Cpi%20%7C%20D%29%20%5Ctextrm%7Bd%7D%20%5Cpi%20%5Cprod%5Climits_%7Bj%3D1%7D%5E%7Bm%7D%20%5Cint%20%5Ctheta_%7Bjc%7D%5E%7B%5Ctextrm%7BI%7D%28x_%7Bjc%7D%3D1%29%7D%281%20-%20%5Ctheta_%7Bjc%7D%29%5E%7B%5Ctextrm%7BI%7D%28x_%7Bjc%7D%3D0%29%7D%20p%28%5Ctheta_%7Bjc%7D%20%7C%20D%29%20%5Ctextrm%7Bd%7D%20%5Ctheta_%7Bjc%7D.)\n",
    "\n",
    "Заметим, что интегралы есть ни что иное, как матожидания по апостериорным распределениям, отсюда\n",
    "![p(y=c|\\textbf{x}, D) \\propto \\bar\\pi_c\\prod\\limits_{j=1}^{m} \\bar\\theta_{jc}^{\\textrm{I}(x_{jc}=1)}(1 - \\bar\\theta_{jc})^{\\textrm{I}(x_{jc}=0)},](https://latex.codecogs.com/gif.latex?p%28y%3Dc%7C%5Ctextbf%7Bx%7D%2C%20D%29%20%5Cpropto%20%5Cbar%5Cpi_c%5Cprod%5Climits_%7Bj%3D1%7D%5E%7Bm%7D%20%5Cbar%5Ctheta_%7Bjc%7D%5E%7B%5Ctextrm%7BI%7D%28x_%7Bjc%7D%3D1%29%7D%281%20-%20%5Cbar%5Ctheta_%7Bjc%7D%29%5E%7B%5Ctextrm%7BI%7D%28x_%7Bjc%7D%3D0%29%7D%2C)\n",
    "\n",
    "где\n",
    "* $\\bar\\pi_c = \\frac{N_c + \\alpha_c}{\\sum N_j + \\sum\\alpha_j}$\n",
    "* $\\bar\\theta_{jc} = \\frac{N_{jc} + \\beta_0}{N_c + \\beta_0 + \\beta_1}$.\n",
    "\n",
    "Окончательно, для наблюдения $\\textbf{x}$ выберем класс с наибольшей вероятностью: $\\hat y = \\operatorname*{arg\\,max}_c p(y=c|\\textbf{x}, D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет\n",
    "\n",
    "Для знакомства с задачей классификации текстов возьмем популярный датасет [20 Newsgroups](http://qwone.com/~jason/20Newsgroups/), предусмотрительно встроенный в пакет ```sklearn```. Датасет состоит из ~20К текстов, классифицированных на 20 категорий. Датасет разбит на ```train``` и ```test```. Для загрузки используем  модуль ```fetch_20newsgroups```, в параметрах есть смысл указать, что мета информацию о тексте загружать не нужно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем список категорий текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Атрибут ```traget``` хранит номера категорий для текстов из обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доступ к самим текстам через атрибут ```data```. Выведем текст и категорию первого примера из обучающего датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic = rec.motorcycles\n",
      "\n",
      "hey... I'm pretty new to the wonderful world of motorcycles... I just\n",
      "bought\n",
      "a used 81 Kaw KZ650 CSR from a friend.... I was just wondering what kind of\n",
      "\n",
      "saddle bags I could get for it (since I know nothing about them)  are there\n",
      "bags for the gas tank?  how much would some cost, and how much do they\n",
      "hold?\n",
      "thanks for your advice!!!  I may be new to riding, but I love it\n",
      "already!!!!\n",
      ":)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 854\n",
    "print('Topic = {0}\\n'.format(newsgroups_train.target_names[newsgroups_train.target[n]]))\n",
    "print(newsgroups_train.data[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторное представление текста\n",
    "\n",
    "Представим текст как вектор индикаторов вхождений слов из некоторого словаря в текст. Это простейшая модель BOF. \n",
    "\n",
    "Сформируем словарь на основе обучающего датасета. Для этого используем модуль ```CountVectorizer```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=None, analyzer='word', binary=True)\n",
    "vectorizer.fit(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество проиндексированных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101631"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проиндексированные слова и их индексы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'was': 95844,\n",
       " 'wondering': 97181,\n",
       " 'if': 48754,\n",
       " 'anyone': 18915,\n",
       " 'out': 68847,\n",
       " 'there': 88638,\n",
       " 'could': 30074,\n",
       " 'enlighten': 37335,\n",
       " 'me': 60560,\n",
       " 'on': 68080,\n",
       " 'this': 88767,\n",
       " 'car': 25775,\n",
       " 'saw': 80623,\n",
       " 'the': 88532,\n",
       " 'other': 68781,\n",
       " 'day': 31990,\n",
       " 'it': 51326,\n",
       " 'door': 34809,\n",
       " 'sports': 84538,\n",
       " 'looked': 57390,\n",
       " 'to': 89360,\n",
       " 'be': 21987,\n",
       " 'from': 41715,\n",
       " 'late': 55746,\n",
       " '60s': 9843,\n",
       " 'early': 35974,\n",
       " '70s': 11174,\n",
       " 'called': 25492,\n",
       " 'bricklin': 24160,\n",
       " 'doors': 34810,\n",
       " 'were': 96247,\n",
       " 'really': 76471,\n",
       " 'small': 83426,\n",
       " 'in': 49447,\n",
       " 'addition': 16809,\n",
       " 'front': 41724,\n",
       " 'bumper': 24635,\n",
       " 'separate': 81658,\n",
       " 'rest': 77878,\n",
       " 'of': 67670,\n",
       " 'body': 23480,\n",
       " 'is': 51136,\n",
       " 'all': 17936,\n",
       " 'know': 54632,\n",
       " 'can': 25590,\n",
       " 'tellme': 88143,\n",
       " 'model': 62746,\n",
       " 'name': 64931,\n",
       " 'engine': 37287,\n",
       " 'specs': 84276,\n",
       " 'years': 99911,\n",
       " 'production': 73373,\n",
       " 'where': 96433,\n",
       " 'made': 59079,\n",
       " 'history': 46814,\n",
       " 'or': 68409,\n",
       " 'whatever': 96395,\n",
       " 'info': 49932,\n",
       " 'you': 100208,\n",
       " 'have': 45885,\n",
       " 'funky': 41979,\n",
       " 'looking': 57393,\n",
       " 'please': 71850,\n",
       " 'mail': 59216,\n",
       " 'fair': 39384,\n",
       " 'number': 66857,\n",
       " 'brave': 24025,\n",
       " 'souls': 84005,\n",
       " 'who': 96532,\n",
       " 'upgraded': 92659,\n",
       " 'their': 88565,\n",
       " 'si': 82550,\n",
       " 'clock': 27947,\n",
       " 'oscillator': 68705,\n",
       " 'shared': 82058,\n",
       " 'experiences': 38725,\n",
       " 'for': 41127,\n",
       " 'poll': 72238,\n",
       " 'send': 81586,\n",
       " 'brief': 24177,\n",
       " 'message': 61072,\n",
       " 'detailing': 33193,\n",
       " 'your': 100221,\n",
       " 'with': 96917,\n",
       " 'procedure': 73321,\n",
       " 'top': 89533,\n",
       " 'speed': 84314,\n",
       " 'attained': 20268,\n",
       " 'cpu': 30295,\n",
       " 'rated': 76104,\n",
       " 'add': 16794,\n",
       " 'cards': 25827,\n",
       " 'and': 18521,\n",
       " 'adapters': 16779,\n",
       " 'heat': 46110,\n",
       " 'sinks': 82882,\n",
       " 'hour': 47434,\n",
       " 'usage': 92860,\n",
       " 'per': 70646,\n",
       " 'floppy': 40823,\n",
       " 'disk': 34077,\n",
       " 'functionality': 41941,\n",
       " '800': 12266,\n",
       " 'floppies': 40821,\n",
       " 'are': 19443,\n",
       " 'especially': 37947,\n",
       " 'requested': 77662,\n",
       " 'will': 96683,\n",
       " 'summarizing': 86304,\n",
       " 'next': 65731,\n",
       " 'two': 90780,\n",
       " 'days': 32005,\n",
       " 'so': 83666,\n",
       " 'network': 65541,\n",
       " 'knowledge': 54643,\n",
       " 'base': 21721,\n",
       " 'done': 34776,\n",
       " 'upgrade': 92656,\n",
       " 'haven': 45887,\n",
       " 'answered': 18779,\n",
       " 'thanks': 88509,\n",
       " 'well': 96219,\n",
       " 'folks': 41046,\n",
       " 'my': 64435,\n",
       " 'mac': 58921,\n",
       " 'plus': 71977,\n",
       " 'finally': 40376,\n",
       " 'gave': 42786,\n",
       " 'up': 92629,\n",
       " 'ghost': 43346,\n",
       " 'weekend': 96141,\n",
       " 'after': 17264,\n",
       " 'starting': 85147,\n",
       " 'life': 56673,\n",
       " 'as': 19756,\n",
       " '512k': 8677,\n",
       " 'way': 95949,\n",
       " 'back': 21280,\n",
       " '1985': 3483,\n",
       " 'sooo': 83940,\n",
       " 'market': 59698,\n",
       " 'new': 65641,\n",
       " 'machine': 58962,\n",
       " 'bit': 22963,\n",
       " 'sooner': 83939,\n",
       " 'than': 88501,\n",
       " 'intended': 50434,\n",
       " 'into': 50684,\n",
       " 'picking': 71337,\n",
       " 'powerbook': 72598,\n",
       " '160': 2940,\n",
       " 'maybe': 60082,\n",
       " '180': 3248,\n",
       " 'bunch': 24643,\n",
       " 'questions': 75295,\n",
       " 'that': 88519,\n",
       " 'hopefully': 47275,\n",
       " 'somebody': 83880,\n",
       " 'answer': 18777,\n",
       " 'does': 34684,\n",
       " 'anybody': 18906,\n",
       " 'any': 18903,\n",
       " 'dirt': 33826,\n",
       " 'when': 96429,\n",
       " 'round': 79239,\n",
       " 'introductions': 50731,\n",
       " 'expected': 38692,\n",
       " 'heard': 46088,\n",
       " '185c': 3301,\n",
       " 'supposed': 86536,\n",
       " 'make': 59298,\n",
       " 'an': 18408,\n",
       " 'appearence': 19100,\n",
       " 'summer': 86307,\n",
       " 'but': 24804,\n",
       " 'anymore': 18913,\n",
       " 'since': 82836,\n",
       " 'don': 34763,\n",
       " 'access': 16419,\n",
       " 'macleak': 59008,\n",
       " 'had': 45321,\n",
       " 'more': 63109,\n",
       " 'has': 45802,\n",
       " 'rumors': 79575,\n",
       " 'about': 16251,\n",
       " 'price': 73151,\n",
       " 'drops': 35182,\n",
       " 'line': 56819,\n",
       " 'like': 56734,\n",
       " 'ones': 68112,\n",
       " 'duo': 35455,\n",
       " 'just': 52999,\n",
       " 'went': 96243,\n",
       " 'through': 88882,\n",
       " 'recently': 76599,\n",
       " 'what': 96391,\n",
       " 'impression': 49380,\n",
       " 'display': 34179,\n",
       " 'probably': 73290,\n",
       " 'swing': 86876,\n",
       " 'got': 44023,\n",
       " '80mb': 12356,\n",
       " 'rather': 76107,\n",
       " '120': 2223,\n",
       " 'feel': 39875,\n",
       " 'how': 47460,\n",
       " 'much': 63885,\n",
       " 'better': 22522,\n",
       " 'yea': 99905,\n",
       " 'looks': 57397,\n",
       " 'great': 44350,\n",
       " 'store': 85576,\n",
       " 'wow': 97354,\n",
       " 'good': 43961,\n",
       " 'solicit': 83829,\n",
       " 'some': 83878,\n",
       " 'opinions': 68273,\n",
       " 'people': 70632,\n",
       " 'use': 92872,\n",
       " 'its': 51394,\n",
       " 'worth': 97321,\n",
       " 'taking': 87613,\n",
       " 'size': 82977,\n",
       " 'money': 62946,\n",
       " 'hit': 46816,\n",
       " 'get': 43217,\n",
       " 'active': 16693,\n",
       " 'realize': 76463,\n",
       " 'real': 76443,\n",
       " 'subjective': 85967,\n",
       " 'question': 75283,\n",
       " 've': 93870,\n",
       " 'only': 68129,\n",
       " 'played': 71818,\n",
       " 'around': 19629,\n",
       " 'machines': 58970,\n",
       " 'computer': 28940,\n",
       " 'breifly': 24096,\n",
       " 'figured': 40269,\n",
       " 'actually': 16718,\n",
       " 'uses': 92896,\n",
       " 'daily': 31686,\n",
       " 'might': 61681,\n",
       " 'prove': 73750,\n",
       " 'helpful': 46276,\n",
       " 'hellcats': 46247,\n",
       " 'perform': 70691,\n",
       " 'advance': 17006,\n",
       " 'email': 36887,\n",
       " 'll': 57131,\n",
       " 'post': 72490,\n",
       " 'summary': 86305,\n",
       " 'news': 65683,\n",
       " 'reading': 76420,\n",
       " 'time': 89092,\n",
       " 'at': 20123,\n",
       " 'premium': 72960,\n",
       " 'finals': 40377,\n",
       " 'corner': 29912,\n",
       " 'tom': 89443,\n",
       " 'willis': 96702,\n",
       " 'twillis': 90755,\n",
       " 'ecn': 36154,\n",
       " 'purdue': 74173,\n",
       " 'edu': 36306,\n",
       " 'electrical': 36687,\n",
       " 'engineering': 37291,\n",
       " 'do': 34601,\n",
       " 'weitek': 96197,\n",
       " 'address': 16821,\n",
       " 'phone': 71183,\n",
       " 'information': 49954,\n",
       " 'chip': 27055,\n",
       " 'article': 19719,\n",
       " 'c5owcb': 25167,\n",
       " 'n3p': 64704,\n",
       " 'world': 97285,\n",
       " 'std': 85234,\n",
       " 'com': 28464,\n",
       " 'by': 24943,\n",
       " 'tombaker': 89454,\n",
       " 'baker': 21446,\n",
       " 'understanding': 91908,\n",
       " 'errors': 37819,\n",
       " 'basically': 21758,\n",
       " 'known': 54648,\n",
       " 'bugs': 24549,\n",
       " 'warning': 95809,\n",
       " 'system': 87099,\n",
       " 'software': 83776,\n",
       " 'things': 88732,\n",
       " 'checked': 26867,\n",
       " 'right': 78397,\n",
       " 'values': 93597,\n",
       " 'yet': 99968,\n",
       " 'because': 22073,\n",
       " 'they': 88694,\n",
       " 'aren': 19450,\n",
       " 'set': 81796,\n",
       " 'till': 89076,\n",
       " 'launch': 55794,\n",
       " 'suchlike': 86163,\n",
       " 'fix': 40536,\n",
       " 'code': 28210,\n",
       " 'possibly': 72489,\n",
       " 'introduce': 50726,\n",
       " 'tell': 88138,\n",
       " 'crew': 30476,\n",
       " 'ok': 67861,\n",
       " 'see': 81407,\n",
       " 'no': 66242,\n",
       " '213': 4520,\n",
       " 'before': 22152,\n",
       " 'liftoff': 56693,\n",
       " 'ignore': 48826,\n",
       " 'course': 30153,\n",
       " 'term': 88273,\n",
       " 'must': 64177,\n",
       " 'rigidly': 78424,\n",
       " 'defined': 32516,\n",
       " 'bill': 22805,\n",
       " 'doubt': 34877,\n",
       " 'she': 82116,\n",
       " 'using': 92909,\n",
       " 'quote': 75377,\n",
       " 'allegedly': 17951,\n",
       " 'her': 46347,\n",
       " 'read': 76409,\n",
       " 'presenting': 73022,\n",
       " 'first': 40480,\n",
       " 'argument': 19491,\n",
       " 'weapons': 96087,\n",
       " 'mass': 59848,\n",
       " 'destruction': 33177,\n",
       " 'commonly': 28634,\n",
       " 'understood': 91918,\n",
       " 'then': 88587,\n",
       " 'switching': 86894,\n",
       " 'topics': 89542,\n",
       " 'point': 72149,\n",
       " 'evidently': 38319,\n",
       " 'show': 82411,\n",
       " 'not': 66511,\n",
       " 'should': 82390,\n",
       " 'allowed': 18014,\n",
       " 'later': 55752,\n",
       " 'analysis': 18462,\n",
       " 'given': 43495,\n",
       " 'consider': 29365,\n",
       " 'another': 18755,\n",
       " 'class': 27750,\n",
       " 'few': 40063,\n",
       " 'responded': 77850,\n",
       " 'request': 77661,\n",
       " 'treatment': 90130,\n",
       " 'astrocytomas': 20067,\n",
       " 'whom': 96548,\n",
       " 'couldn': 30076,\n",
       " 'thank': 88504,\n",
       " 'directly': 33811,\n",
       " 'bouncing': 23801,\n",
       " 'probs': 73310,\n",
       " 'sean': 81281,\n",
       " 'debra': 32202,\n",
       " 'sharon': 82070,\n",
       " 'thought': 88819,\n",
       " 'publicly': 74010,\n",
       " 'everyone': 38296,\n",
       " 'sure': 86578,\n",
       " 'glad': 43584,\n",
       " 'accidentally': 16436,\n",
       " 'rn': 78818,\n",
       " 'instead': 50320,\n",
       " 'rm': 78753,\n",
       " 'trying': 90421,\n",
       " 'delete': 32652,\n",
       " 'file': 40308,\n",
       " 'last': 55730,\n",
       " 'september': 81686,\n",
       " 'hmmm': 46947,\n",
       " 'shows': 82435,\n",
       " 'scsi': 81148,\n",
       " 'controler': 29647,\n",
       " 'range': 76016,\n",
       " 'indeed': 49653,\n",
       " '5mb': 9463,\n",
       " 'controller': 29653,\n",
       " '6mb': 10776,\n",
       " '10mb': 1883,\n",
       " 'burst': 24750,\n",
       " 'note': 66523,\n",
       " 'increase': 49609,\n",
       " 'quadra': 75158,\n",
       " 'version': 94111,\n",
       " 'exist': 38622,\n",
       " 'pc': 70336,\n",
       " 'too': 89502,\n",
       " 'mode': 62741,\n",
       " '16': 2939,\n",
       " 'wide': 96601,\n",
       " 'fast': 39596,\n",
       " '12mb': 2402,\n",
       " '20mb': 4463,\n",
       " '32': 6203,\n",
       " '15': 2777,\n",
       " '40mb': 7521,\n",
       " 'own': 69216,\n",
       " 'data': 31883,\n",
       " 'although': 18123,\n",
       " 'twice': 90746,\n",
       " 'esdi': 37909,\n",
       " 'correct': 29944,\n",
       " 'reach': 76387,\n",
       " 'which': 96454,\n",
       " '20': 4306,\n",
       " 'faster': 39603,\n",
       " 'ide': 48648,\n",
       " '96': 13781,\n",
       " 'these': 88679,\n",
       " 'facts': 39331,\n",
       " 'been': 22129,\n",
       " 'posted': 72502,\n",
       " 'newsgroup': 65696,\n",
       " 'ibm': 48485,\n",
       " 'sheet': 82145,\n",
       " 'available': 20615,\n",
       " 'ftp': 41832,\n",
       " 'sumex': 86290,\n",
       " 'aim': 17521,\n",
       " 'stanford': 85085,\n",
       " '36': 6576,\n",
       " '44': 7699,\n",
       " 'report': 77569,\n",
       " 'compare': 28701,\n",
       " 'txt': 90812,\n",
       " '173': 3156,\n",
       " '161': 2956,\n",
       " 'may': 60078,\n",
       " 'still': 85440,\n",
       " 'part': 69994,\n",
       " 'problem': 73302,\n",
       " 'both': 23761,\n",
       " 'inconsiant': 49578,\n",
       " 'though': 88817,\n",
       " 'documented': 34656,\n",
       " 'apple': 19122,\n",
       " 'salesperson': 80307,\n",
       " 'said': 80257,\n",
       " 'maximum': 60067,\n",
       " 'synchronous': 87031,\n",
       " 'ansynchronous': 18782,\n",
       " 'slower': 83355,\n",
       " 'seems': 81427,\n",
       " 'interface': 50511,\n",
       " 'think': 88735,\n",
       " 'driven': 35152,\n",
       " 'true': 90363,\n",
       " 'go': 43814,\n",
       " 'win': 96727,\n",
       " 'downloaded': 34925,\n",
       " 'several': 81849,\n",
       " 'icons': 48578,\n",
       " 'bmp': 23369,\n",
       " 'figure': 40268,\n",
       " 'change': 26709,\n",
       " 'wallpaper': 95716,\n",
       " 'help': 46271,\n",
       " 'would': 97332,\n",
       " 'appreciated': 19190,\n",
       " 'thanx': 88516,\n",
       " 'brando': 23999,\n",
       " 'board': 23425,\n",
       " 'over': 68997,\n",
       " 'year': 99908,\n",
       " 'work': 97250,\n",
       " 'diskdoubler': 34080,\n",
       " 'autodoubler': 20534,\n",
       " 'due': 35371,\n",
       " 'licensing': 56637,\n",
       " 'stac': 84986,\n",
       " 'technologies': 88013,\n",
       " 'owners': 69219,\n",
       " 'compression': 28887,\n",
       " 'technology': 88014,\n",
       " 'writing': 97469,\n",
       " 'memory': 60909,\n",
       " 'lost': 57474,\n",
       " 'reference': 76902,\n",
       " 'wrong': 97481,\n",
       " 'problems': 73307,\n",
       " 'being': 22219,\n",
       " 'hard': 45667,\n",
       " 'say': 80633,\n",
       " 'whether': 96446,\n",
       " 'fault': 39648,\n",
       " 'something': 83899,\n",
       " 'else': 36848,\n",
       " 'however': 47469,\n",
       " 'decompress': 32330,\n",
       " 'troubled': 90338,\n",
       " 'recompress': 76690,\n",
       " 'without': 96940,\n",
       " 'icon': 48568,\n",
       " 'usually': 92955,\n",
       " 'reappears': 76497,\n",
       " 'above': 16252,\n",
       " 'mentioned': 60961,\n",
       " 'freeware': 41595,\n",
       " 'expansion': 38680,\n",
       " 'utility': 93008,\n",
       " 'dd': 32096,\n",
       " 'expand': 38670,\n",
       " 'compressed': 28882,\n",
       " 'unless': 92248,\n",
       " 'installed': 50304,\n",
       " 'product': 73371,\n",
       " 'now': 66588,\n",
       " 'unlikely': 92253,\n",
       " 'holes': 47088,\n",
       " 'related': 77195,\n",
       " 'fixed': 40541,\n",
       " 'sad': 80184,\n",
       " 'makes': 59308,\n",
       " 'very': 94140,\n",
       " 'reluctant': 77310,\n",
       " 'buy': 24849,\n",
       " 're': 76378,\n",
       " 'stinky': 85465,\n",
       " 'hey': 46480,\n",
       " 'competition': 28782,\n",
       " 'ducati': 35351,\n",
       " '900gts': 13404,\n",
       " '1978': 3473,\n",
       " '17k': 3230,\n",
       " 'runs': 79600,\n",
       " 'paint': 69644,\n",
       " 'bronze': 24291,\n",
       " 'brown': 24323,\n",
       " 'orange': 68421,\n",
       " 'faded': 39342,\n",
       " 'leaks': 56016,\n",
       " 'oil': 67825,\n",
       " 'pops': 72366,\n",
       " '1st': 4107,\n",
       " 'accel': 16384,\n",
       " 'shop': 82338,\n",
       " 'trans': 89902,\n",
       " 'leak': 56011,\n",
       " 'sold': 83810,\n",
       " 'bike': 22778,\n",
       " 'owner': 69218,\n",
       " 'want': 95762,\n",
       " '3495': 6425,\n",
       " 'am': 18165,\n",
       " 'thinking': 88741,\n",
       " '3k': 7148,\n",
       " 'nice': 65878,\n",
       " 'stable': 84983,\n",
       " 'mate': 59908,\n",
       " 'beemer': 22127,\n",
       " 'jap': 51912,\n",
       " 'call': 25484,\n",
       " 'myself': 64510,\n",
       " 'axis': 20842,\n",
       " 'motors': 63276,\n",
       " 'tuba': 90522,\n",
       " 'irwin': 51132,\n",
       " 'honk': 47229,\n",
       " 'therefore': 88645,\n",
       " 'computrac': 28953,\n",
       " 'richardson': 78322,\n",
       " 'tx': 90791,\n",
       " 'cmptrc': 28076,\n",
       " 'lonestar': 57360,\n",
       " 'org': 68511,\n",
       " 'dod': 34661,\n",
       " '0826': 784,\n",
       " 'r75': 75686,\n",
       " 'yep': 99949,\n",
       " 'pretty': 73106,\n",
       " 'jew': 52174,\n",
       " 'understand': 91904,\n",
       " 'jewish': 52179,\n",
       " 'jews': 52183,\n",
       " 'believe': 22267,\n",
       " 'covenant': 30181,\n",
       " 'between': 22529,\n",
       " 'yhwh': 100033,\n",
       " 'patriarchs': 70202,\n",
       " 'abraham': 16260,\n",
       " 'moses': 63193,\n",
       " 'case': 25968,\n",
       " 'establishes': 37990,\n",
       " 'moral': 63092,\n",
       " 'follow': 41050,\n",
       " 'mankind': 59507,\n",
       " 'even': 38256,\n",
       " 'decide': 32264,\n",
       " 'boundaries': 23803,\n",
       " 'fall': 39429,\n",
       " 'sadducees': 80196,\n",
       " 'believed': 22268,\n",
       " 'torah': 89568,\n",
       " 'required': 77671,\n",
       " 'whereas': 96435,\n",
       " 'pharisees': 71079,\n",
       " 'ancestors': 18507,\n",
       " 'modern': 62780,\n",
       " 'judaism': 52863,\n",
       " 'interpretation': 50603,\n",
       " 'lead': 55991,\n",
       " 'morality': 63096,\n",
       " 'nuances': 66824,\n",
       " 'talmud': 87656,\n",
       " 'essence': 37972,\n",
       " 'biblical': 22702,\n",
       " 'man': 59408,\n",
       " 'christian': 27206,\n",
       " 'necessarily': 65304,\n",
       " 'indicate': 49696,\n",
       " 'anything': 18921,\n",
       " 'outside': 68953,\n",
       " 'relationship': 77203,\n",
       " 'one': 68102,\n",
       " 'speculate': 84299,\n",
       " 'trouble': 90337,\n",
       " 'we': 96061,\n",
       " 'created': 30421,\n",
       " 'his': 46789,\n",
       " 'image': 49088,\n",
       " 'means': 60609,\n",
       " 'different': 33606,\n",
       " 'come': 28502,\n",
       " 'conclusion': 29039,\n",
       " 'upsets': 92711,\n",
       " 'cart': 25928,\n",
       " 'wants': 95767,\n",
       " 'script': 81110,\n",
       " 'shaky': 82008,\n",
       " 'foundation': 41357,\n",
       " 'mix': 62186,\n",
       " 'metaphors': 61131,\n",
       " 'unashamedly': 91676,\n",
       " 'living': 57028,\n",
       " 'christ': 27196,\n",
       " 'example': 38458,\n",
       " 'little': 56992,\n",
       " 'jesus': 52157,\n",
       " 'person': 70834,\n",
       " 'recorded': 76722,\n",
       " 'utterances': 93049,\n",
       " 'narratives': 64998,\n",
       " 'followers': 41053,\n",
       " 'references': 76904,\n",
       " 'comtemporary': 28964,\n",
       " 'historians': 46807,\n",
       " 'revelation': 78076,\n",
       " 'aside': 19846,\n",
       " 'second': 81335,\n",
       " 'hand': 45528,\n",
       " 'worse': 97308,\n",
       " 'attempt': 20279,\n",
       " 'debunk': 32215,\n",
       " 'christianity': 27210,\n",
       " 'seem': 81423,\n",
       " 'initially': 50077,\n",
       " 'bible': 22698,\n",
       " 'interpret': 50602,\n",
       " 'humanity': 47774,\n",
       " 'guess': 44748,\n",
       " 'faith': 39405,\n",
       " 'relevation': 77243,\n",
       " 'comes': 28508,\n",
       " 'inherent': 50038,\n",
       " 'subjectiveness': 85969,\n",
       " 'absolute': 16291,\n",
       " 'undoubtably': 91962,\n",
       " 'multiple': 63997,\n",
       " 'codes': 28223,\n",
       " 'founded': 41359,\n",
       " 'parent': 69918,\n",
       " 'child': 27010,\n",
       " 'never': 65617,\n",
       " 'swear': 86812,\n",
       " 'assume': 20013,\n",
       " 'swears': 86814,\n",
       " 'simply': 82797,\n",
       " 'told': 89425,\n",
       " 'trooper': 90326,\n",
       " 'pub': 73995,\n",
       " 'bar': 21593,\n",
       " 'children': 27020,\n",
       " 'wrongness': 97486,\n",
       " 'here': 46366,\n",
       " 'disobeys': 34123,\n",
       " 'inappropriate': 49481,\n",
       " 'quite': 75354,\n",
       " 'happy': 45643,\n",
       " 'animals': 18631,\n",
       " 'analogy': 18454,\n",
       " 'hold': 47074,\n",
       " 'water': 95889,\n",
       " 'knows': 54649,\n",
       " 'he': 46025,\n",
       " 'same': 80369,\n",
       " 'type': 90846,\n",
       " 'gist': 43483,\n",
       " 'incidentally': 49527,\n",
       " 'young': 100212,\n",
       " 'considers': 29374,\n",
       " 'directive': 33809,\n",
       " 'until': 92512,\n",
       " 'gets': 43245,\n",
       " 'older': 67943,\n",
       " 'piaget': 71313,\n",
       " 'learns': 56039,\n",
       " 'david': 31954,\n",
       " 'religion': 77274,\n",
       " 'description': 33054,\n",
       " 'external': 38873,\n",
       " 'tank': 87704,\n",
       " 'option': 68350,\n",
       " 'ssf': 84877,\n",
       " 'redesign': 76802,\n",
       " 'deleted': 32653,\n",
       " 'yo': 100173,\n",
       " 'ken': 53860,\n",
       " 'let': 56312,\n",
       " 'keep': 53810,\n",
       " 'wingless': 96794,\n",
       " 'orbiter': 68437,\n",
       " 'options': 68354,\n",
       " 'list': 56933,\n",
       " 'today': 89388,\n",
       " '23': 4670,\n",
       " 'edition': 36271,\n",
       " 'york': 100197,\n",
       " 'times': 89111,\n",
       " 'reports': 77578,\n",
       " 'connor': 29298,\n",
       " 'panel': 69756,\n",
       " 'proposals': 73624,\n",
       " 'dropped': 35180,\n",
       " 'such': 86162,\n",
       " 'giant': 43367,\n",
       " 'fuel': 41882,\n",
       " 'tanks': 87711,\n",
       " 'used': 92875,\n",
       " 'launching': 55799,\n",
       " 'space': 84097,\n",
       " 'shuttles': 82506,\n",
       " 'building': 24562,\n",
       " 'station': 85191,\n",
       " 'existing': 38633,\n",
       " 'shuttle': 82505,\n",
       " 'wings': 96798,\n",
       " 'tail': 87575,\n",
       " 'removed': 77399,\n",
       " 'currently': 31052,\n",
       " 'three': 88850,\n",
       " 'considered': 29372,\n",
       " 'presented': 73018,\n",
       " 'advisory': 17060,\n",
       " 'meeting': 60754,\n",
       " 'yesterday': 99965,\n",
       " 'reported': 77573,\n",
       " 'low': 57530,\n",
       " 'cost': 30042,\n",
       " 'modular': 62812,\n",
       " 'approach': 19209,\n",
       " 'studied': 85845,\n",
       " 'team': 87968,\n",
       " 'msfc': 63730,\n",
       " 'teams': 87973,\n",
       " 'jsc': 52794,\n",
       " 'larc': 55680,\n",
       " 'supporting': 86531,\n",
       " 'srt': 84818,\n",
       " 'crystal': 30770,\n",
       " 'city': 27557,\n",
       " 'lerc': 56280,\n",
       " 'reston': 77894,\n",
       " 'also': 18091,\n",
       " 'site': 82935,\n",
       " 'locations': 57270,\n",
       " 'helping': 46279,\n",
       " 'respective': 77841,\n",
       " 'activities': 16700,\n",
       " 'key': 53947,\n",
       " 'features': 39835,\n",
       " 'bus': 24762,\n",
       " 'developed': 33295,\n",
       " 'lockheed': 57276,\n",
       " 'qualified': 75182,\n",
       " 'sts': 85822,\n",
       " 'elv': 36868,\n",
       " 'provides': 73768,\n",
       " 'propulsion': 73651,\n",
       " 'gn': 43774,\n",
       " 'communications': 28657,\n",
       " 'management': 59419,\n",
       " 'air': 17541,\n",
       " 'force': 41139,\n",
       " 'power': 72592,\n",
       " 'capability': 25706,\n",
       " 'obtained': 67471,\n",
       " 'flights': 40765,\n",
       " 'solar': 83802,\n",
       " 'arrays': 19650,\n",
       " 'provide': 73762,\n",
       " 'kw': 55111,\n",
       " 'vehicle': 93926,\n",
       " 'flies': 40763,\n",
       " 'arrow': 19682,\n",
       " 'optimize': 68343,\n",
       " 'microgravity': 61579,\n",
       " 'environment': 37499,\n",
       " 'spacelab': 84110,\n",
       " 'missions': 62099,\n",
       " 'utilize': 93010,\n",
       " 'vehilce': 93929,\n",
       " 'source': 84028,\n",
       " '30': 6044,\n",
       " 'human': 47765,\n",
       " 'tended': 88200,\n",
       " 'opposed': 68300,\n",
       " 'old': 67939,\n",
       " 'sexist': 81876,\n",
       " 'achieved': 16572,\n",
       " 'us': 92842,\n",
       " 'common': 28630,\n",
       " 'module': 62817,\n",
       " 'modified': 62798,\n",
       " 'lab': 55423,\n",
       " 'docking': 34629,\n",
       " 'ports': 72428,\n",
       " 'added': 16798,\n",
       " 'international': 50570,\n",
       " 'partners': 70054,\n",
       " 'labs': 55450,\n",
       " 'place': 71712,\n",
       " 'nodes': 66280,\n",
       " 'docked': 34626,\n",
       " '60': 9762,\n",
       " 'habitability': 45296,\n",
       " 'eva': 38207,\n",
       " 'nasda': 65017,\n",
       " 'esa': 37863,\n",
       " 'modules': 62818,\n",
       " 'permanent': 70750,\n",
       " 'presence': 73011,\n",
       " '3rd': 7312,\n",
       " 'habitation': 45300,\n",
       " 'acrv': 16673,\n",
       " 'assured': 20025,\n",
       " 'return': 78035,\n",
       " 'freedom': 41576,\n",
       " 'derived': 33004,\n",
       " 'based': 21731,\n",
       " 'mike': 61711,\n",
       " 'griffin': 44454,\n",
       " 'alot': 18062,\n",
       " 'design': 33083,\n",
       " 'love': 57516,\n",
       " 'assumes': 20015,\n",
       " 'lightweight': 56724,\n",
       " 'assembly': 19947,\n",
       " 'computed': 28939,\n",
       " '51': 8668,\n",
       " 'inclination': 49536,\n",
       " 'orbit': 68433,\n",
       " 'build': 24557,\n",
       " 'occurs': 67531,\n",
       " 'six': 82963,\n",
       " 'phases': 71092,\n",
       " 'initial': 50067,\n",
       " 'research': 77706,\n",
       " 'reached': 76389,\n",
       " 'transferred': 89948,\n",
       " 'visits': 94506,\n",
       " 'adopted': 16954,\n",
       " 'non': 66324,\n",
       " 'language': 55620,\n",
       " 'deployed': 32927,\n",
       " '10': 1469,\n",
       " 'keeping': 53814,\n",
       " 'sometimes': 83904,\n",
       " 'orbiters': 68438,\n",
       " 'logistics': 57334,\n",
       " 'supply': 86523,\n",
       " 'tolerance': 89428,\n",
       " '14': 2593,\n",
       " '2nd': 5688,\n",
       " 'thermal': 88654,\n",
       " 'control': 29644,\n",
       " 'radiator': 75831,\n",
       " 'internationals': 50575,\n",
       " 'finish': 40417,\n",
       " '24': 4749,\n",
       " 'most': 63215,\n",
       " 'systems': 87112,\n",
       " 'exception': 38487,\n",
       " 'major': 59286,\n",
       " 'changes': 26717,\n",
       " 'reduced': 76838,\n",
       " 'prices': 73155,\n",
       " 'forsale': 41293,\n",
       " 'behalf': 22185,\n",
       " 'brother': 24312,\n",
       " 'moving': 63353,\n",
       " 'moved': 63340,\n",
       " 'already': 18086,\n",
       " 'offer': 67699,\n",
       " 'black': 23072,\n",
       " 'decker': 32292,\n",
       " 'duster': 35506,\n",
       " 'portable': 72407,\n",
       " 'vaccum': 93514,\n",
       " 'purchased': 74167,\n",
       " '12': 2222,\n",
       " 'sr': 84757,\n",
       " '1000': 1471,\n",
       " 'dual': 35328,\n",
       " 'cassette': 25994,\n",
       " 'player': 71819,\n",
       " 'fm': 40906,\n",
       " 'band': 21529,\n",
       " 'graphics': 44261,\n",
       " 'equalizer': 37666,\n",
       " 'high': 46648,\n",
       " 'dubing': 35342,\n",
       " 'tape': 87729,\n",
       " 'deck': 32289,\n",
       " 'treble': 90136,\n",
       " 'sound': 84008,\n",
       " 'bet': 22500,\n",
       " 'fixable': 40537,\n",
       " '80': 12265,\n",
       " '25': 4899,\n",
       " 'monolux': 62991,\n",
       " 'zoom': 101286,\n",
       " 'microscope': 61606,\n",
       " '1200x': 2230,\n",
       " 'magnification': 59162,\n",
       " 'japan': 51913,\n",
       " 'includes': 49544,\n",
       " 'accessories': 16430,\n",
       " '50': 8581,\n",
       " 'sunbeam': 86336,\n",
       " '1400': 2595,\n",
       " 'hair': 45378,\n",
       " 'dryer': 35223,\n",
       " 'put': 74240,\n",
       " 'head': 46032,\n",
       " 'under': 91833,\n",
       " 'salons': 80333,\n",
       " 'ask': 19853,\n",
       " 'why': 96576,\n",
       " 'bro': 24240,\n",
       " 'everylast': 38295,\n",
       " 'bag': 21394,\n",
       " 'leather': 56050,\n",
       " 'brand': 23995,\n",
       " 'osterizer': 68758,\n",
       " 'pusle': 74239,\n",
       " 'matic': 59946,\n",
       " 'blender': 23178,\n",
       " 'speeds': 84328,\n",
       " 'cookbook': 29748,\n",
       " 'binolux': 22870,\n",
       " 'binoculars': 22869,\n",
       " '7x35': 12225,\n",
       " 'extra': 38891,\n",
       " 'angle': 18601,\n",
       " '525ft': 8740,\n",
       " '1000yds': 1536,\n",
       " 'proctor': 73353,\n",
       " 'silex': 82713,\n",
       " 'spray': 84581,\n",
       " 'steam': 85258,\n",
       " 'dry': 35220,\n",
       " 'iron': 51061,\n",
       " 'contact': 29499,\n",
       " 'thru': 88899,\n",
       " 'reply': 77560,\n",
       " 'expeditously': 38702,\n",
       " 'always': 18161,\n",
       " 'included': 49541,\n",
       " 'lastly': 55737,\n",
       " 'reasonable': 76510,\n",
       " 'look': 57387,\n",
       " 'happened': 45633,\n",
       " 'japanese': 51915,\n",
       " 'citizens': 27548,\n",
       " 'during': 35493,\n",
       " 'war': 95770,\n",
       " 'ii': 48875,\n",
       " 'prepared': 72972,\n",
       " 'stick': 85417,\n",
       " 'them': 88578,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс, например, для слова anyone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('anyone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь преобразуем строку в вектор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I was wondering if anyone out there could enlighten me on this car I saw'\n",
    "x = vectorizer.transform([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой тип имеет объект, на который указывает ```x```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разреженная матрица!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отступление про разреженные матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список ненулевых элементов матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы строк и столбцов для ненулевых элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([18915, 25775, 30074, 37335, 48754, 60560, 68080, 68847, 80623,\n",
       "        88638, 88767, 95844, 97181]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование к объекту ndarray (именно после приведения к такому виду разреженные матрицы можно подставлять в функции, например, библиотеки Numpy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к словарю. Раскодируем вектор ```x``` в список слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['anyone', 'car', 'could', 'enlighten', 'if', 'me', 'on', 'out',\n",
       "        'saw', 'there', 'this', 'was', 'wondering'], dtype='<U81')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропало слово ```I```. Но дело в том, что по умолчанию ```CountVectorizer``` отбрасывает последовательности, короче 2 символов. На это указывает параметр ```token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b'```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем весь набор текстов обучающего датасета в набор векторов, получим матрицу ```X_train```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 101631)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О пользе разреженных матриц. Отношение числа ненулевых элементов ко всем элементам матрицы ```X_train```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009597982275882548"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nnz / np.prod(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```BernoulliNB``` - байесовский классификатор для бинаризованных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(alpha=1).fit(X_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Априорные вероятности для категорий (как получились эти числа?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04242531, 0.05161747, 0.05223617, 0.05214778, 0.05108715,\n",
       "       0.05241294, 0.05170585, 0.05250133, 0.05285487, 0.05276648,\n",
       "       0.05303164, 0.05258971, 0.05223617, 0.05250133, 0.05241294,\n",
       "       0.05294326, 0.04825879, 0.04984974, 0.04109952, 0.03332155])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем по 10 самых значимых слов в каждой категории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: not you in it is and that of to the\n",
      "comp.graphics: on that it is for in of and to the\n",
      "comp.os.ms-windows.misc: that windows for of in is and it to the\n",
      "comp.sys.ibm.pc.hardware: with in that for of it is and to the\n",
      "comp.sys.mac.hardware: with in for that it of and is to the\n",
      "comp.windows.x: that this for it in is of and to the\n",
      "misc.forsale: is have or with of in to and the for\n",
      "rec.autos: you for that is it in of and to the\n",
      "rec.motorcycles: you that for is in it of and to the\n",
      "rec.sport.baseball: have it for is that of in and to the\n",
      "rec.sport.hockey: on it for is that of in and to the\n",
      "sci.crypt: for this in it is and that of to the\n",
      "sci.electronics: you that it for in is of and to the\n",
      "sci.med: this for that in it is and of to the\n",
      "sci.space: on for that it is in and of to the\n",
      "soc.religion.christian: not for it that is in and to of the\n",
      "talk.politics.guns: you for is it that in and of to the\n",
      "talk.politics.mideast: you not it is that in and of to the\n",
      "talk.politics.misc: you for is it in that and of to the\n",
      "talk.religion.misc: are not it in that is and of to the\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в топ попали общеупотребительные слова, неспецифичные для какой-либо категории. С этим еще предстоит разобраться, в пока запустим метод ```predict``` на тестовой части датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение тестовой части датасета и формирование матрицы признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_test = vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск метода ```predict```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем набор метрик классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394,), (3,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(newsgroups_test.target == 2)[0].shape, np.where(predicts==2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       1.00      0.01      0.02       319\n",
      "           comp.graphics       0.60      0.47      0.52       389\n",
      " comp.os.ms-windows.misc       0.33      0.00      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.45      0.71      0.55       392\n",
      "   comp.sys.mac.hardware       0.46      0.69      0.55       385\n",
      "          comp.windows.x       0.83      0.39      0.54       395\n",
      "            misc.forsale       0.75      0.74      0.75       390\n",
      "               rec.autos       0.41      0.68      0.51       396\n",
      "         rec.motorcycles       0.17      0.94      0.28       398\n",
      "      rec.sport.baseball       0.64      0.80      0.71       397\n",
      "        rec.sport.hockey       0.99      0.51      0.67       399\n",
      "               sci.crypt       0.67      0.37      0.47       396\n",
      "         sci.electronics       0.55      0.53      0.54       393\n",
      "                 sci.med       0.90      0.35      0.50       396\n",
      "               sci.space       0.81      0.34      0.48       394\n",
      "  soc.religion.christian       0.38      0.60      0.47       398\n",
      "      talk.politics.guns       0.67      0.23      0.34       364\n",
      "   talk.politics.mideast       0.89      0.38      0.53       376\n",
      "      talk.politics.misc       0.85      0.07      0.14       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "               micro avg       0.46      0.46      0.46      7532\n",
      "               macro avg       0.62      0.44      0.43      7532\n",
      "            weighted avg       0.62      0.46      0.44      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(newsgroups_test.target, predicts,\n",
    "                            target_names=newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель явно нужно улучшать. В первую очередь, есть смысл обратить внимание на вектор признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель Bag-of-Words\n",
    "\n",
    "При построении вектора признаков будем учитывать не просто факт вхождения слова в текст, а подсчитывать количество вхождений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(binary=False)\n",
    "X_train_counts = count_vect.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера выведем слова вместе и количеством вхождений для первого текста из обучающего датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mail': 1,\n",
       " 'please': 1,\n",
       " 'looking': 1,\n",
       " 'funky': 1,\n",
       " 'have': 1,\n",
       " 'you': 1,\n",
       " 'info': 1,\n",
       " 'whatever': 1,\n",
       " 'or': 1,\n",
       " 'history': 1,\n",
       " 'made': 1,\n",
       " 'where': 1,\n",
       " 'production': 1,\n",
       " 'years': 1,\n",
       " 'specs': 1,\n",
       " 'engine': 1,\n",
       " 'name': 1,\n",
       " 'model': 1,\n",
       " 'tellme': 1,\n",
       " 'can': 1,\n",
       " 'know': 1,\n",
       " 'all': 1,\n",
       " 'is': 2,\n",
       " 'body': 1,\n",
       " 'of': 2,\n",
       " 'rest': 1,\n",
       " 'separate': 1,\n",
       " 'bumper': 1,\n",
       " 'front': 1,\n",
       " 'addition': 1,\n",
       " 'in': 1,\n",
       " 'small': 1,\n",
       " 'really': 1,\n",
       " 'were': 1,\n",
       " 'doors': 1,\n",
       " 'bricklin': 1,\n",
       " 'called': 1,\n",
       " '70s': 1,\n",
       " 'early': 1,\n",
       " '60s': 1,\n",
       " 'late': 1,\n",
       " 'from': 2,\n",
       " 'be': 1,\n",
       " 'to': 1,\n",
       " 'looked': 1,\n",
       " 'sports': 1,\n",
       " 'door': 1,\n",
       " 'it': 2,\n",
       " 'day': 1,\n",
       " 'other': 1,\n",
       " 'the': 6,\n",
       " 'saw': 1,\n",
       " 'car': 4,\n",
       " 'this': 4,\n",
       " 'on': 2,\n",
       " 'me': 1,\n",
       " 'enlighten': 1,\n",
       " 'could': 1,\n",
       " 'there': 1,\n",
       " 'out': 1,\n",
       " 'anyone': 2,\n",
       " 'if': 2,\n",
       " 'wondering': 1,\n",
       " 'was': 4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(count_vect.inverse_transform(X_train_counts[0])[0], X_train_counts[0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобное предстваление текста называется Bag-of-Words (BOF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MultinomialNB``` - байесовский классификатор для категоризованных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_counts, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим новую модель на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.15      0.25       319\n",
      "           comp.graphics       0.63      0.60      0.62       389\n",
      " comp.os.ms-windows.misc       0.33      0.00      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.54      0.66      0.60       392\n",
      "   comp.sys.mac.hardware       0.82      0.42      0.55       385\n",
      "          comp.windows.x       0.53      0.81      0.64       395\n",
      "            misc.forsale       0.88      0.55      0.68       390\n",
      "               rec.autos       0.85      0.54      0.66       396\n",
      "         rec.motorcycles       0.95      0.40      0.57       398\n",
      "      rec.sport.baseball       0.97      0.56      0.71       397\n",
      "        rec.sport.hockey       0.57      0.78      0.66       399\n",
      "               sci.crypt       0.40      0.79      0.53       396\n",
      "         sci.electronics       0.70      0.38      0.49       393\n",
      "                 sci.med       0.82      0.67      0.74       396\n",
      "               sci.space       0.73      0.64      0.68       394\n",
      "  soc.religion.christian       0.32      0.93      0.47       398\n",
      "      talk.politics.guns       0.60      0.43      0.50       364\n",
      "   talk.politics.mideast       0.37      0.81      0.51       376\n",
      "      talk.politics.misc       0.30      0.41      0.35       310\n",
      "      talk.religion.misc       0.55      0.02      0.05       251\n",
      "\n",
      "               micro avg       0.54      0.54      0.54      7532\n",
      "               macro avg       0.62      0.53      0.51      7532\n",
      "            weighted avg       0.63      0.54      0.53      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(newsgroups_test.data)\n",
    "predicts = clf.predict(X_test_counts)\n",
    "print(classification_report(newsgroups_test.target, predicts, target_names=newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-прежнему лидируют неспецифичные слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: not you it in and that is to of the\n",
      "comp.graphics: that you it in for is of and to the\n",
      "comp.os.ms-windows.misc: of it is and b8f g9v to the max ax\n",
      "comp.sys.ibm.pc.hardware: with in that for it of is and to the\n",
      "comp.sys.mac.hardware: with that for in it is of and to the\n",
      "comp.windows.x: that on it for in is of and to the\n",
      "misc.forsale: you is it 00 in of to and for the\n",
      "rec.autos: for you that it is in of and to the\n",
      "rec.motorcycles: for you that is in it of and to the\n",
      "rec.sport.baseball: it for he is that in of and to the\n",
      "rec.sport.hockey: he it is for that of in and to the\n",
      "sci.crypt: for be it that in is and of to the\n",
      "sci.electronics: that for you it in is and of to the\n",
      "sci.med: you for it that is in and to of the\n",
      "sci.space: on it that for is in and to of the\n",
      "soc.religion.christian: you not it in is that and to of the\n",
      "talk.politics.guns: for you it is that in and of to the\n",
      "talk.politics.mideast: you they it is that in to and of the\n",
      "talk.politics.misc: for you it is in that and of to the\n",
      "talk.religion.misc: not it you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, count_vect, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пора от них избавиться, убрав из словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, binary=False)\n",
    "X_train_counts = count_vect.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.30      0.41       319\n",
      "           comp.graphics       0.58      0.69      0.63       389\n",
      " comp.os.ms-windows.misc       0.40      0.01      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.53      0.72      0.61       392\n",
      "   comp.sys.mac.hardware       0.74      0.56      0.64       385\n",
      "          comp.windows.x       0.56      0.81      0.66       395\n",
      "            misc.forsale       0.85      0.69      0.76       390\n",
      "               rec.autos       0.82      0.70      0.76       396\n",
      "         rec.motorcycles       0.91      0.62      0.73       398\n",
      "      rec.sport.baseball       0.94      0.74      0.83       397\n",
      "        rec.sport.hockey       0.58      0.91      0.71       399\n",
      "               sci.crypt       0.54      0.79      0.64       396\n",
      "         sci.electronics       0.71      0.49      0.58       393\n",
      "                 sci.med       0.81      0.79      0.80       396\n",
      "               sci.space       0.72      0.75      0.73       394\n",
      "  soc.religion.christian       0.46      0.91      0.61       398\n",
      "      talk.politics.guns       0.57      0.61      0.59       364\n",
      "   talk.politics.mideast       0.58      0.80      0.67       376\n",
      "      talk.politics.misc       0.46      0.44      0.45       310\n",
      "      talk.religion.misc       0.56      0.06      0.11       251\n",
      "\n",
      "               micro avg       0.63      0.63      0.63      7532\n",
      "               macro avg       0.65      0.62      0.60      7532\n",
      "            weighted avg       0.65      0.63      0.61      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(newsgroups_test.data)\n",
    "predicts = clf.predict(X_test_counts)\n",
    "print(classification_report(newsgroups_test.target, predicts,\n",
    "                            target_names=newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще несколько процентов точности прибавила модель! Теперь в топе более осмысленные слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: atheists believe say atheism does just think don people god\n",
      "comp.graphics: software images files data use file jpeg edu graphics image\n",
      "comp.os.ms-windows.misc: 34u windows 1d9 145 pl a86 b8f g9v max ax\n",
      "comp.sys.ibm.pc.hardware: does bus ide use drives disk controller card scsi drive\n",
      "comp.sys.mac.hardware: just bit does know like problem use drive apple mac\n",
      "comp.windows.x: output entry widget motif edu server program use window file\n",
      "misc.forsale: price 20 shipping offer dos 10 50 sale new 00\n",
      "rec.autos: think know engine new good don just like cars car\n",
      "rec.motorcycles: motorcycle time ride good know don dod like just bike\n",
      "rec.sport.baseball: games like just 00 don think team good game year\n",
      "rec.sport.hockey: 12 11 season 55 play 25 hockey 10 game team\n",
      "sci.crypt: keys privacy people clipper government chip use db encryption key\n",
      "sci.electronics: good does know used ground wire don power like use\n",
      "sci.med: time com know like medical use health people don edu\n",
      "sci.space: just shuttle time orbit data like earth launch nasa space\n",
      "soc.religion.christian: christ don believe know does think church people jesus god\n",
      "talk.politics.guns: just weapons right law firearms don guns file people gun\n",
      "talk.politics.mideast: don israeli know jews turkish israel said armenians armenian people\n",
      "talk.politics.misc: going just government know stephanopoulos don think president mr people\n",
      "talk.religion.misc: know say christian think just bible don jesus people god\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, count_vect, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пойдем дальше по пути улучшения признакового описания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF - мера значимости слова для документа, рассчитывается как произведение величины Term Frequency (частота вхождения слова в документ) на величину Inverse Document Frequency (обратная величина к доле документов в датасете, в которых встречается данное слово). Часто в формуле расчета TF-IDF можно встретить логарифмы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим словарь и расчитаем меры IDF для слов обучающего датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS).fit(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тексты обучающего датасета в вектора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = vectorizer.transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ненулевые элементы векторов содержат значения меры TF-IDF для слов из документа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09418459, 0.13703598, 0.25808578, 0.16368393, 0.16329311,\n",
       "       0.11339407, 0.14613089, 0.12706904, 0.12197187, 0.08978258,\n",
       "       0.1614203 , 0.13037295, 0.10043854, 0.10634736, 0.13520842,\n",
       "       0.13822597, 0.06961998, 0.11869933, 0.12504221, 0.2245489 ,\n",
       "       0.20599311, 0.14341273, 0.12667096, 0.17300821, 0.1484788 ,\n",
       "       0.10526009, 0.46579831, 0.10548299, 0.19644481, 0.24723135,\n",
       "       0.12937103, 0.14077746, 0.20599311, 0.20797701])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем слова из первого документа в порядке увеличения из меры TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['know', 'really', 'years', 'mail', 'day', 'called', 'looking',\n",
       "       'small', 'info', 'rest', 'history', 'early', 'saw', 'body',\n",
       "       'model', 'looked', 'wondering', 'late', 'addition', 'engine',\n",
       "       'separate', 'door', 'production', 'specs', 'sports', 'doors',\n",
       "       'bumper', 'enlighten', '70s', '60s', 'funky', 'bricklin', 'tellme',\n",
       "       'car'], dtype='<U81')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X_train_vectors[0])[0][np.argsort(X_train_vectors[0].data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и было задумано, в начале списка оказались общеупотребительные слова (know, really, years), а ближе к концу списка  - слова, характерные именно для данного документа (bumper, 60s, bricklin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель MultinomialNB (как адаптировать модель MultinomialNB для нецелых признаков?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_vectors, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ-лист слов по категориям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: islam atheists say just religion atheism think don people god\n",
      "comp.graphics: looking format 3d know program file files thanks image graphics\n",
      "comp.os.ms-windows.misc: card problem thanks driver drivers use files dos file windows\n",
      "comp.sys.ibm.pc.hardware: monitor disk thanks pc ide controller bus card scsi drive\n",
      "comp.sys.mac.hardware: know monitor does quadra simms thanks problem drive apple mac\n",
      "comp.windows.x: using windows x11r5 use application thanks widget server motif window\n",
      "misc.forsale: asking email sell price condition new shipping offer 00 sale\n",
      "rec.autos: don ford new good dealer just engine like cars car\n",
      "rec.motorcycles: don just helmet riding like motorcycle ride bikes dod bike\n",
      "rec.sport.baseball: braves players pitching hit runs games game baseball team year\n",
      "rec.sport.hockey: league year nhl games season players play hockey team game\n",
      "sci.crypt: people use escrow nsa keys government chip clipper encryption key\n",
      "sci.electronics: don thanks voltage used know does like circuit power use\n",
      "sci.med: skepticism cadre dsl banks chastity n3jxp pitt gordon geb msg\n",
      "sci.space: just lunar earth shuttle like moon launch orbit nasa space\n",
      "soc.religion.christian: believe faith christian christ bible people christians church jesus god\n",
      "talk.politics.guns: just law firearms government fbi don weapons people guns gun\n",
      "talk.politics.mideast: said arabs arab turkish people armenians armenian jews israeli israel\n",
      "talk.politics.misc: know state clinton president just think tax don government people\n",
      "talk.religion.misc: think don koresh objective christians bible people christian jesus god\n"
     ]
    }
   ],
   "source": [
    "show_top10(clf, count_vect, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики модели на тестовом датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.76      0.18      0.28       319\n",
      "           comp.graphics       0.67      0.69      0.68       389\n",
      " comp.os.ms-windows.misc       0.66      0.58      0.62       394\n",
      "comp.sys.ibm.pc.hardware       0.60      0.74      0.66       392\n",
      "   comp.sys.mac.hardware       0.77      0.67      0.71       385\n",
      "          comp.windows.x       0.81      0.77      0.79       395\n",
      "            misc.forsale       0.78      0.76      0.77       390\n",
      "               rec.autos       0.84      0.73      0.78       396\n",
      "         rec.motorcycles       0.87      0.74      0.80       398\n",
      "      rec.sport.baseball       0.92      0.80      0.85       397\n",
      "        rec.sport.hockey       0.57      0.93      0.71       399\n",
      "               sci.crypt       0.59      0.79      0.67       396\n",
      "         sci.electronics       0.72      0.52      0.60       393\n",
      "                 sci.med       0.89      0.76      0.82       396\n",
      "               sci.space       0.77      0.74      0.76       394\n",
      "  soc.religion.christian       0.37      0.93      0.53       398\n",
      "      talk.politics.guns       0.57      0.71      0.63       364\n",
      "   talk.politics.mideast       0.81      0.79      0.80       376\n",
      "      talk.politics.misc       0.89      0.28      0.43       310\n",
      "      talk.religion.misc       1.00      0.01      0.02       251\n",
      "\n",
      "               micro avg       0.68      0.68      0.68      7532\n",
      "               macro avg       0.74      0.66      0.65      7532\n",
      "            weighted avg       0.74      0.68      0.66      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "predicts = clf.predict(X_test_vectors)\n",
    "print(classification_report(newsgroups_test.target, predicts,\n",
    "                            target_names=newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: gipu presupposition presumable dionetics uproarious abducted interrogationum interpretationa abberation elee\n",
      "comp.graphics: ove outwards criiterion outrunning outputing outliers cricket equalities tw13 visualizer\n",
      "comp.os.ms-windows.misc: om9xax 82c607 82bbzt _supercharging hix 3958784 auh 395z auie 3iirlj103j1\n",
      "comp.sys.ibm.pc.hardware: suggeted me2 allister assisatnce 2350 libc 8800cs 02h drdos6 persnickity\n",
      "comp.sys.mac.hardware: cayman pqrqkcu3 pqxjnlyrlpq3c networkable ezr3 tarrifs efisher am29000 worldscript catchup\n",
      "comp.windows.x: 8vao est5edt popen_xphigs llat popen_ws fractionally nassestr wellorganized bursty n86pl\n",
      "misc.forsale: carring morefonts morbius 4x1mb 4x6 removeable xwin isifisher terkel 90x9403\n",
      "rec.autos: olof citroen olde yjs vavau gearboxes bellevue gearshift opdbs tercel\n",
      "rec.motorcycles: lotta spooge xz550 sportmax springers sprocket sprockets squeak sported me77\n",
      "rec.sport.baseball: tantrum tanstaafl riles huckabay slyke dhenderson 30s drayton scoresheets ma_ind25\n",
      "rec.sport.hockey: looming dade virta loraas loria doodah vincent_damphousse hipocracy dale_hawerchuk martin_rucinsky\n",
      "sci.crypt: wiretappers phreakers phred wireline emboldens 71571 71441 physto wiretapped originations\n",
      "sci.electronics: murashie municipalities _exact_ multivibrators _first_ _fluorescent_ multipling multiplexing mycal ýé\n",
      "sci.med: matise matias maternal 33136 masseur watery watertown watersheds mcmahon invertebrate\n",
      "sci.space: gaten gastronomical gastronomic nonterrestrial noonday noontime gasing gaseous beaming new_probes\n",
      "soc.religion.christian: signposts pitting domini vaya unfaithfully unfaithful pius saracens sardes shamed\n",
      "talk.politics.guns: gangsters mane manes inundate 7mn _implies_ intruders c_z9 hofstadter qj0\n",
      "talk.politics.mideast: yazmasi kaisser basim permision monument hatin wirklich gioia likudnik tomorrrow\n",
      "talk.politics.misc: efficent kuril kumthekar kulaks kukis efm steeves steinbeck stephanopoulos skyrocketed\n",
      "talk.religion.misc: _basis_ indgil satanism ekr headlong arbab arbiter mena indebted baalbek\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf=ComplementNB().fit(X_train_vectors,newsgroups_train.target)\n",
    "show_top10(clf,count_vect,newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.31      0.42      0.35       319\n",
      "           comp.graphics       0.72      0.72      0.72       389\n",
      " comp.os.ms-windows.misc       0.70      0.61      0.65       394\n",
      "comp.sys.ibm.pc.hardware       0.64      0.71      0.67       392\n",
      "   comp.sys.mac.hardware       0.76      0.73      0.74       385\n",
      "          comp.windows.x       0.82      0.79      0.81       395\n",
      "            misc.forsale       0.77      0.74      0.76       390\n",
      "               rec.autos       0.82      0.75      0.78       396\n",
      "         rec.motorcycles       0.84      0.77      0.81       398\n",
      "      rec.sport.baseball       0.92      0.83      0.88       397\n",
      "        rec.sport.hockey       0.84      0.93      0.89       399\n",
      "               sci.crypt       0.74      0.81      0.77       396\n",
      "         sci.electronics       0.70      0.55      0.62       393\n",
      "                 sci.med       0.83      0.81      0.82       396\n",
      "               sci.space       0.80      0.80      0.80       394\n",
      "  soc.religion.christian       0.53      0.90      0.67       398\n",
      "      talk.politics.guns       0.58      0.73      0.64       364\n",
      "   talk.politics.mideast       0.80      0.85      0.82       376\n",
      "      talk.politics.misc       0.66      0.42      0.51       310\n",
      "      talk.religion.misc       0.48      0.10      0.16       251\n",
      "\n",
      "               micro avg       0.71      0.71      0.71      7532\n",
      "               macro avg       0.71      0.70      0.69      7532\n",
      "            weighted avg       0.72      0.71      0.71      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicts = clf.predict(X_test_vectors)\n",
    "print(classification_report(newsgroups_test.target, predicts,target_names=newsgroups_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прибавили еще несколько процентов. Можно лучше!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
